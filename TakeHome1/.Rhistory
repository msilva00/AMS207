df = as.data.frame(matrix(result,ncol=ncolumns,byrow=TRUE))
}
url_string = 'https://github.com/msilva00/AMS207/blob/master/TakeHome1/BirdDat.csv'
data_start_keyword = '1968'
ncolumns = 4
getData = function(url_string, data_start_keyword, ncolumns){
thepage = readLines(url_string)
index_start = grep(data_start_keyword,thepage)
start_parse = thepage[index_start]
startlocation1 = str_locate(start_parse, " *")[,2] + 1
endlocation1 = str_locate(start_parse, data_start_keyword)[,1] - 1
mypattern1 = substr(start_parse, startlocation, endlocation)
startlocation2 = str_locate(start_parse, data_start_keyword)[,2] + 1
endlocation2 = nchar(start_parse)
mypattern2 = substr(start_parse, startlocation2, endlocation2)
mypattern = paste(mypattern1, "([^<]*)", mypattern2, sep = "")
datalines = grep(mypattern,thepage[index_start:length(thepage)],value=TRUE)
getexpr = function(s,g)substring(s,g,g+attr(g,'match.length')-1)
gg = gregexpr(mypattern,datalines)
matches = mapply(getexpr,datalines,gg)
result = gsub(mypattern,'\\1',matches)
names(result) = NULL
df = as.data.frame(matrix(result,ncol=ncolumns,byrow=TRUE))
return(df)
}
# Example
url_string = 'https://github.com/msilva00/AMS207/blob/master/TakeHome1/BirdDat.csv'
data_start_keyword = '1968'
ncolumns = 4
getWebsiteData = function(url_string, data_start_keyword, ncolumns){
thepage = readLines(url_string)
index_start = grep(data_start_keyword,thepage)
start_parse = thepage[index_start]
startlocation1 = str_locate(start_parse, " *")[,2] + 1
endlocation1 = str_locate(start_parse, data_start_keyword)[,1] - 1
mypattern1 = substr(start_parse, startlocation, endlocation)
startlocation2 = str_locate(start_parse, data_start_keyword)[,2] + 1
endlocation2 = nchar(start_parse)
mypattern2 = substr(start_parse, startlocation2, endlocation2)
mypattern = paste(mypattern1, "([^<]*)", mypattern2, sep = "")
datalines = grep(mypattern,thepage[index_start:length(thepage)],value=TRUE)
getexpr = function(s,g)substring(s,g,g+attr(g,'match.length')-1)
gg = gregexpr(mypattern,datalines)
matches = mapply(getexpr,datalines,gg)
result = gsub(mypattern,'\\1',matches)
names(result) = NULL
df = as.data.frame(matrix(result,ncol=ncolumns,byrow=TRUE))
return(df)
}
BirdDat = getWebsiteData(url_string = url_string, data_start_keyword = data_start_keyword, ncolumns = 4)
BirdDat
# Example From Wikipedia
url_wiki = "https://en.wikipedia.org/wiki/List_of_Nobel_laureates"
data_start_keyword = 'Year'
Nobels = getWebsiteData(url_string =  url_wiki, "Year", ncolumns = 4)
url_string = "https://en.wikipedia.org/wiki/List_of_Nobel_laureates"
data_start_keyword = 'Year'
ncolumns = 7
thepage = readLines(url_string)
index_start = grep(data_start_keyword,thepage)
index_start
secondary_keyword = "Physics"
# look for the nearest secondary keyword
neighbor = grep(secondary_keyword,thepage)
neighbor
length(index_start)
length(neighbor)
c(index_start, neighbor)
poss_indexes =c(index_start, neighbor)
sort(dist(poss_indexes))
distance = sort(dist(poss_indexes))
distance[distance[1]]
distance[1]
if(distance[1] != distance[2]){
print("distance one is smallest")
}
if(distance[1] == distance[2]){
print("distance one is smallest")
}
unsorted_dists = dist(poss_indexes)
unsorted_dists
unsorted_dists = dist(neighbor, index_start)
unsorted_dists = dist(c(neighbor, index_start))
unsorted_dists
# look for the nearest secondary keyword
neighbor = grep(secondary_keyword,thepage)
neighbor
# look for the nearest secondary keyword
paste(data_start_keyword, secondary_keyword)
# look for the nearest secondary keyword
paste(data_start_keyword, ".", secondary_keyword)
# look for the nearest secondary keyword
twowords = paste(data_start_keyword, ".", secondary_keyword)
twowords
# look for the nearest secondary keyword
twowords = paste(data_start_keyword, "([^<]*)", secondary_keyword)
twowords
# look for the nearest secondary keyword
twowords = paste(data_start_keyword, "([^<]*)", secondary_keyword, sep = "")
twowords
neighbor = grep(secondary_keyword,thepage)
neighbor
neighbor = grep(twowords,thepage)
neighbor
getWebsiteData = function(url_string, data_start_keyword, secondary_keyword,ncolumns){
thepage = readLines(url_string)
index_start = grep(data_start_keyword,thepage)
if(index_start > 1){
return("error")
}
}
getWebsiteData = function(url_string, data_start_keyword, secondary_keyword,ncolumns){
getWebsiteData = function(url_string, data_start_keyword, secondary_keyword,ncolumns){
getWebsiteData = function(url_string, data_start_keyword, secondary_keyword,ncolumns){
thepage = readLines(url_string)
index_start = grep(data_start_keyword,thepage)
if(index_start > 1){
return("error")
}else{start_parse = thepage[index_start]
startlocation1 = str_locate(start_parse, " *")[,2] + 1
endlocation1 = str_locate(start_parse, data_start_keyword)[,1] - 1
mypattern1 = substr(start_parse, startlocation, endlocation)
startlocation2 = str_locate(start_parse, data_start_keyword)[,2] + 1
endlocation2 = nchar(start_parse)
mypattern2 = substr(start_parse, startlocation2, endlocation2)
mypattern = paste(mypattern1, "([^<]*)", mypattern2, sep = "")
datalines = grep(mypattern,thepage[index_start:length(thepage)],value=TRUE)
getexpr = function(s,g)substring(s,g,g+attr(g,'match.length')-1)
gg = gregexpr(mypattern,datalines)
matches = mapply(getexpr,datalines,gg)
result = gsub(mypattern,'\\1',matches)
names(result) = NULL
df = as.data.frame(matrix(result,ncol=ncolumns,byrow=TRUE))
return(df)
}
}
# Example From Wikipedia
url_wiki = "https://en.wikipedia.org/wiki/List_of_Nobel_laureates"
data_start_keyword = 'Year'
# Example From Wikipedia
url_wiki = "https://en.wikipedia.org/wiki/List_of_Nobel_laureates"
data_start_keyword = 'Year'
Nobels = getWebsiteData(url_string =  url_wiki, "Year", ncolumns = 7)
Nobels
getWebsiteData = function(url_string, data_start_keyword, secondary_keyword,ncolumns){
thepage = readLines(url_string)
index_start = grep(data_start_keyword,thepage)
if(index_start > 1){
print("ERROR")
return(NA)
}else{start_parse = thepage[index_start]
startlocation1 = str_locate(start_parse, " *")[,2] + 1
endlocation1 = str_locate(start_parse, data_start_keyword)[,1] - 1
mypattern1 = substr(start_parse, startlocation, endlocation)
startlocation2 = str_locate(start_parse, data_start_keyword)[,2] + 1
endlocation2 = nchar(start_parse)
mypattern2 = substr(start_parse, startlocation2, endlocation2)
mypattern = paste(mypattern1, "([^<]*)", mypattern2, sep = "")
datalines = grep(mypattern,thepage[index_start:length(thepage)],value=TRUE)
getexpr = function(s,g)substring(s,g,g+attr(g,'match.length')-1)
gg = gregexpr(mypattern,datalines)
matches = mapply(getexpr,datalines,gg)
result = gsub(mypattern,'\\1',matches)
names(result) = NULL
df = as.data.frame(matrix(result,ncol=ncolumns,byrow=TRUE))
return(df)
}
}
# Example From Github
url_string = 'https://github.com/msilva00/AMS207/blob/master/TakeHome1/BirdDat.csv'
data_start_keyword = '1968'
ncolumns = 4
BirdDat = getWebsiteData(url_string = url_string, data_start_keyword = data_start_keyword, ncolumns = 4)
# Example From Wikipedia
url_wiki = "https://en.wikipedia.org/wiki/List_of_Nobel_laureates"
data_start_keyword = 'Year'
Nobels = getWebsiteData(url_string =  url_wiki, "Year", ncolumns = 7)
Nobels
)
getWebsiteData = function(url_string, data_start_keyword, secondary_keyword,ncolumns){
thepage = readLines(url_string)
index_start = grep(data_start_keyword,thepage)
if(index_start > 1){
print("ERROR")
return(NA)
}else{start_parse = thepage[index_start]
startlocation1 = str_locate(start_parse, " *")[,2] + 1
endlocation1 = str_locate(start_parse, data_start_keyword)[,1] - 1
mypattern1 = substr(start_parse, startlocation, endlocation)
startlocation2 = str_locate(start_parse, data_start_keyword)[,2] + 1
endlocation2 = nchar(start_parse)
mypattern2 = substr(start_parse, startlocation2, endlocation2)
mypattern = paste(mypattern1, "([^<]*)", mypattern2, sep = "")
datalines = grep(mypattern,thepage[index_start:length(thepage)],value=TRUE)
getexpr = function(s,g)substring(s,g,g+attr(g,'match.length')-1)
gg = gregexpr(mypattern,datalines)
matches = mapply(getexpr,datalines,gg)
result = gsub(mypattern,'\\1',matches)
names(result) = NULL
df = as.data.frame(matrix(result,ncol=ncolumns,byrow=TRUE))
return(df)
}
}
# Example From Wikipedia
url_wiki = "https://en.wikipedia.org/wiki/List_of_Nobel_laureates"
data_start_keyword = 'Year'
Nobels = getWebsiteData(url_string =  url_wiki, "Year", ncolumns = 7)
index_start
url_string = "https://en.wikipedia.org/wiki/List_of_Nobel_laureates"
data_start_keyword = 'Year'
secondary_keyword = "Physics"
ncolumns = 7
thepage = readLines(url_string)
index_start = grep(data_start_keyword,thepage)
index_start
thepage = readLines(url_string)
index_start = grep(data_start_keyword,thepage)
if(index_start > 1){
print(thepage[index_start[1]])
return(NA)
}else{start_parse = thepage[index_start]
startlocation1 = str_locate(start_parse, " *")[,2] + 1
endlocation1 = str_locate(start_parse, data_start_keyword)[,1] - 1
mypattern1 = substr(start_parse, startlocation, endlocation)
startlocation2 = str_locate(start_parse, data_start_keyword)[,2] + 1
endlocation2 = nchar(start_parse)
mypattern2 = substr(start_parse, startlocation2, endlocation2)
mypattern = paste(mypattern1, "([^<]*)", mypattern2, sep = "")
datalines = grep(mypattern,thepage[index_start:length(thepage)],value=TRUE)
getexpr = function(s,g)substring(s,g,g+attr(g,'match.length')-1)
gg = gregexpr(mypattern,datalines)
matches = mapply(getexpr,datalines,gg)
result = gsub(mypattern,'\\1',matches)
names(result) = NULL
df = as.data.frame(matrix(result,ncol=ncolumns,byrow=TRUE))
return(df)
}
if(index_start > 1){
print(thepage[index_start[1]])
return(NA)
}
print(thepage[index_start[1]])
print(thepage[index_start[2]])
print(thepage[index_start[1]] + 1)
print(thepage[index_start[1]:index_start[1]+10])
print(thepage[index_start[2]:index_start[2]+10])
index_start[1]
index_start[2]
print(thepage[index_start[1]-1:index_start[1]+10])
print(thepage[index_start[1]-1:index_start[1]+1])
print(thepage[index_start[2]-1:index_start[2]+1])
print(thepage[index_start[2]-1:index_start[2]+1])
print(thepage[index_start[2]:index_start[2]+1])
print(thepage[index_start[1]:index_start[1]+2])
print(thepage[index_start[2]:index_start[2]+2])
getWebsiteData = function(url_string, data_start_keyword, secondary_keyword,ncolumns){
thepage = readLines(url_string)
index_start = grep(data_start_keyword,thepage)
if(index_start > 1){
print("I havent fixed this bug yet")
return(NA)
}  else{start_parse = thepage[index_start]
startlocation1 = str_locate(start_parse, " *")[,2] + 1
endlocation1 = str_locate(start_parse, data_start_keyword)[,1] - 1
mypattern1 = substr(start_parse, startlocation, endlocation)
startlocation2 = str_locate(start_parse, data_start_keyword)[,2] + 1
endlocation2 = nchar(start_parse)
mypattern2 = substr(start_parse, startlocation2, endlocation2)
mypattern = paste(mypattern1, "([^<]*)", mypattern2, sep = "")
datalines = grep(mypattern,thepage[index_start:length(thepage)],value=TRUE)
getexpr = function(s,g)substring(s,g,g+attr(g,'match.length')-1)
gg = gregexpr(mypattern,datalines)
matches = mapply(getexpr,datalines,gg)
result = gsub(mypattern,'\\1',matches)
names(result) = NULL
df = as.data.frame(matrix(result,ncol=ncolumns,byrow=TRUE))
return(df)
}
}
# Example From Github
url_string = 'https://github.com/msilva00/AMS207/blob/master/TakeHome1/BirdDat.csv'
data_start_keyword = '1968'
ncolumns = 4
BirdDat = getWebsiteData(url_string = url_string, data_start_keyword = data_start_keyword, ncolumns = 4)
BirdDat
getWebsiteData = function(url_string, data_start_keyword, secondary_keyword,ncolumns){
thepage = readLines(url_string)
index_start = grep(data_start_keyword,thepage)
if(index_start > 1){
print("I havent fixed this bug yet")
return(NA)
}  else{start_parse = thepage[index_start]
startlocation1 = str_locate(start_parse, " *")[,2] + 1
endlocation1 = str_locate(start_parse, data_start_keyword)[,1] - 1
mypattern1 = substr(start_parse, startlocation, endlocation)
startlocation2 = str_locate(start_parse, data_start_keyword)[,2] + 1
endlocation2 = nchar(start_parse)
mypattern2 = substr(start_parse, startlocation2, endlocation2)
mypattern = paste(mypattern1, "([^<]*)", mypattern2, sep = "")
datalines = grep(mypattern,thepage[index_start:length(thepage)],value=TRUE)
getexpr = function(s,g)substring(s,g,g+attr(g,'match.length')-1)
gg = gregexpr(mypattern,datalines)
matches = mapply(getexpr,datalines,gg)
result = gsub(mypattern,'\\1',matches)
names(result) = NULL
df = as.data.frame(matrix(result,ncol=ncolumns,byrow=TRUE))
return(df)
}
}
# Example From Github
url_string = 'https://github.com/msilva00/AMS207/blob/master/TakeHome1/BirdDat.csv'
data_start_keyword = '1968'
ncolumns = 4
BirdDat = getWebsiteData(url_string = url_string, data_start_keyword = data_start_keyword, ncolumns = 4)
getWebsiteData = function(url_string, data_start_keyword, secondary_keyword,ncolumns){
thepage = readLines(url_string)
index_start = grep(data_start_keyword,thepage)
if(index_start > 1){
print("I havent fixed this bug yet")
return(NA)
} else{start_parse = thepage[index_start]
startlocation1 = str_locate(start_parse, " *")[,2] + 1
endlocation1 = str_locate(start_parse, data_start_keyword)[,1] - 1
mypattern1 = substr(start_parse, startlocation, endlocation)
startlocation2 = str_locate(start_parse, data_start_keyword)[,2] + 1
endlocation2 = nchar(start_parse)
mypattern2 = substr(start_parse, startlocation2, endlocation2)
mypattern = paste(mypattern1, "([^<]*)", mypattern2, sep = "")
datalines = grep(mypattern,thepage[index_start:length(thepage)],value=TRUE)
getexpr = function(s,g)substring(s,g,g+attr(g,'match.length')-1)
gg = gregexpr(mypattern,datalines)
matches = mapply(getexpr,datalines,gg)
result = gsub(mypattern,'\\1',matches)
names(result) = NULL
df = as.data.frame(matrix(result,ncol=ncolumns,byrow=TRUE))
return(df)
}
}
# Example From Github
url_string = 'https://github.com/msilva00/AMS207/blob/master/TakeHome1/BirdDat.csv'
data_start_keyword = '1968'
ncolumns = 4
BirdDat = getWebsiteData(url_string = url_string, data_start_keyword = data_start_keyword, ncolumns = 4)
getWebsiteData = function(url_string, data_start_keyword, secondary_keyword = "hfuirahui",ncolumns){
thepage = readLines(url_string)
index_start = grep(data_start_keyword,thepage)
if(index_start > 1){
print("I havent fixed this bug yet")
return(NA)
} else{start_parse = thepage[index_start]
startlocation1 = str_locate(start_parse, " *")[,2] + 1
endlocation1 = str_locate(start_parse, data_start_keyword)[,1] - 1
mypattern1 = substr(start_parse, startlocation, endlocation)
startlocation2 = str_locate(start_parse, data_start_keyword)[,2] + 1
endlocation2 = nchar(start_parse)
mypattern2 = substr(start_parse, startlocation2, endlocation2)
mypattern = paste(mypattern1, "([^<]*)", mypattern2, sep = "")
datalines = grep(mypattern,thepage[index_start:length(thepage)],value=TRUE)
getexpr = function(s,g)substring(s,g,g+attr(g,'match.length')-1)
gg = gregexpr(mypattern,datalines)
matches = mapply(getexpr,datalines,gg)
result = gsub(mypattern,'\\1',matches)
names(result) = NULL
df = as.data.frame(matrix(result,ncol=ncolumns,byrow=TRUE))
return(df)
}
}
# Example From Github
url_string = 'https://github.com/msilva00/AMS207/blob/master/TakeHome1/BirdDat.csv'
data_start_keyword = '1968'
ncolumns = 4
BirdDat = getWebsiteData(url_string = url_string, data_start_keyword = data_start_keyword, ncolumns = 4)
getWebsiteData = function(url_string, data_start_keyword, ncolumns){
thepage = readLines(url_string)
index_start = grep(data_start_keyword,thepage)
start_parse = thepage[index_start]
startlocation1 = str_locate(start_parse, " *")[,2] + 1
endlocation1 = str_locate(start_parse, data_start_keyword)[,1] - 1
mypattern1 = substr(start_parse, startlocation, endlocation)
startlocation2 = str_locate(start_parse, data_start_keyword)[,2] + 1
endlocation2 = nchar(start_parse)
mypattern2 = substr(start_parse, startlocation2, endlocation2)
mypattern = paste(mypattern1, "([^<]*)", mypattern2, sep = "")
datalines = grep(mypattern,thepage[index_start:length(thepage)],value=TRUE)
getexpr = function(s,g)substring(s,g,g+attr(g,'match.length')-1)
gg = gregexpr(mypattern,datalines)
matches = mapply(getexpr,datalines,gg)
result = gsub(mypattern,'\\1',matches)
names(result) = NULL
df = as.data.frame(matrix(result,ncol=ncolumns,byrow=TRUE))
return(df)
}
# Example From Github
url_string = 'https://github.com/msilva00/AMS207/blob/master/TakeHome1/BirdDat.csv'
data_start_keyword = '1968'
ncolumns = 4
BirdDat = getWebsiteData(url_string = url_string, data_start_keyword = data_start_keyword, ncolumns = 4)
# Example From Github
url_string = 'https://github.com/msilva00/AMS207/blob/master/TakeHome1/BirdDat.csv'
data_start_keyword = '1968'
thepage = readLines(url_string)
thepage
index_start = grep(data_start_keyword,thepage)
index_start
start_parse = thepage[index_start]
start_parse
startlocation1 = str_locate(start_parse, " *")[,2] + 1
startlocation1
endlocation1 = str_locate(start_parse, data_start_keyword)[,1] - 1
mypattern1 = substr(start_parse, startlocation, endlocation)
mypattern1 = substr(start_parse, startlocation1, endlocation)
startlocation2 = str_locate(start_parse, data_start_keyword)[,2] + 1
mypattern1 = substr(start_parse, startlocation1, endlocation1)
getWebsiteData = function(url_string, data_start_keyword, ncolumns){
thepage = readLines(url_string)
index_start = grep(data_start_keyword,thepage)
start_parse = thepage[index_start]
startlocation1 = str_locate(start_parse, " *")[,2] + 1
endlocation1 = str_locate(start_parse, data_start_keyword)[,1] - 1
mypattern1 = substr(start_parse, startlocation1, endlocation1)
startlocation2 = str_locate(start_parse, data_start_keyword)[,2] + 1
endlocation2 = nchar(start_parse)
mypattern2 = substr(start_parse, startlocation2, endlocation2)
mypattern = paste(mypattern1, "([^<]*)", mypattern2, sep = "")
datalines = grep(mypattern,thepage[index_start:length(thepage)],value=TRUE)
getexpr = function(s,g)substring(s,g,g+attr(g,'match.length')-1)
gg = gregexpr(mypattern,datalines)
matches = mapply(getexpr,datalines,gg)
result = gsub(mypattern,'\\1',matches)
names(result) = NULL
df = as.data.frame(matrix(result,ncol=ncolumns,byrow=TRUE))
return(df)
}
# Example From Github
url_string = 'https://github.com/msilva00/AMS207/blob/master/TakeHome1/BirdDat.csv'
data_start_keyword = '1968'
ncolumns = 4
BirdDat = getWebsiteData(url_string = url_string, data_start_keyword = data_start_keyword, ncolumns = 4)
length(index_start)
getWebsiteData = function(url_string, data_start_keyword, ncolumns){
thepage = readLines(url_string)
index_start = grep(data_start_keyword,thepage)
if(length(index_start) > 1){
print("I haven't fixed this bug yet")
}else{
start_parse = thepage[index_start]
startlocation1 = str_locate(start_parse, " *")[,2] + 1
endlocation1 = str_locate(start_parse, data_start_keyword)[,1] - 1
mypattern1 = substr(start_parse, startlocation1, endlocation1)
startlocation2 = str_locate(start_parse, data_start_keyword)[,2] + 1
endlocation2 = nchar(start_parse)
mypattern2 = substr(start_parse, startlocation2, endlocation2)
mypattern = paste(mypattern1, "([^<]*)", mypattern2, sep = "")
datalines = grep(mypattern,thepage[index_start:length(thepage)],value=TRUE)
getexpr = function(s,g)substring(s,g,g+attr(g,'match.length')-1)
gg = gregexpr(mypattern,datalines)
matches = mapply(getexpr,datalines,gg)
result = gsub(mypattern,'\\1',matches)
names(result) = NULL
df = as.data.frame(matrix(result,ncol=ncolumns,byrow=TRUE))
return(df)
}
}
# Example From Github
url_string = 'https://github.com/msilva00/AMS207/blob/master/TakeHome1/BirdDat.csv'
data_start_keyword = '1968'
ncolumns = 4
BirdDat = getWebsiteData(url_string = url_string, data_start_keyword = data_start_keyword, ncolumns = 4)
# IMDB Box office
url2 = "https://www.imdb.com/chart/boxoffice"
getWebsiteData(url_string = url2, data_start_keyword = "Title", ncolumns = 4)
IMDB = getWebsiteData(url_string = url2, data_start_keyword = "Title", ncolumns = 4)
# IMDB Box office
url_string = "https://www.imdb.com/chart/boxoffice"
data_start_keyword = "Title"
thepage = readLines(url_string)
index_start = grep(data_start_keyword,thepage)
index_start
IMDB = getWebsiteData(url_string = "The Curse of La Llorona", data_start_keyword = "Title", ncolumns = 4)
IMDB = getWebsiteData(url_string = url2, data_start_keyword = "The Curse of La Llorona", ncolumns = 4)
IMDB = getWebsiteData(url_string = url2, data_start_keyword = "The Curse of La Llorona", ncolumns = 4)
data_start_keyword = "The Curse of La Llorona"
# USGS Data
url2 = "https://www.pwrc.usgs.gov/BBS/PublicDataInterface/index.cfm"
data_start_keyword = "Species List"
data_start_keyword =
IMDB = getWebsiteData(url_string = url2, data_start_keyword = "Species List", ncolumns = ((2017-1966) + 1))
url_string = url2
data_start_keyword = "Species List"
thepage = readLines(url_string)
index_start = grep(data_start_keyword,thepage)
index_start
data_start_keyword =
IMDB = getWebsiteData(url_string = url2, data_start_keyword = "Species List", ncolumns = ((2017-1966) + 1))
# USGS Data
url2 = "https://www.pwrc.usgs.gov/BBS/PublicDataInterface/index.cfm"
IMDB = getWebsiteData(url_string = url2, data_start_keyword = "Species List", ncolumns = ((2017-1966) + 1))
url_string
thepage = readLines(url_string)
index_start = grep(data_start_keyword,thepage)
index_start
IMDB = getWebsiteData(url_string = url2, data_start_keyword = "Route Count", ncolumns = ((2017-1966) + 1))
url_string = url2
data_start_keyword = "Route Count"
thepage = readLines(url_string)
index_start = grep(data_start_keyword,thepage)
index_start
data_start_keyword
url_string
gitstring = "https://raw.githubusercontent.com/msilva00/AMS207/master/TakeHome1/BirdDat.csv"
BirdDat <- read.csv(text=getURL(gitstring))
BirdDat
